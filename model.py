# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VgDJxsbm6whaFl0GizMM2uzDdIxW5I4J

# **BISNIS UNDERSTANDING**

**Description**

The dataset provides insights into student lifestyle patterns and their relationship with stress levels and academic performance. It includes various lifestyle attributes such as study hours, sleep duration, physical activity, social hours, extracurricular activities, and GPA, which collectively influence students' stress levels.

# **IMPORTS AND SETUP**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from IPython.display import display

from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import RobustScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import StackingClassifier
from sklearn.pipeline import Pipeline

from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, accuracy_score, classification_report

import warnings
warnings.filterwarnings("ignore")

"""# **LOAD DATA**"""

from google.colab import drive
drive.mount('/content/drive')

Path = 'drive/My Drive/Kaggle'

df = pd.read_csv(Path + '/student_lifestyle_dataset.csv')
df.head(50)

# Display basic information about the dataset
print("Shape of the dataset:", df.shape)
display(df.head())
print("\nDataset Information:")
print(df.info())
print("\nStatistical Summary:")
display(df.describe().T)

"""# **EXPLORATORY DATA ANALYSIS**"""

column_name = 'Stress_Level'
plt.figure(figsize=(10, 4))

# First subplot: Count plot
plt.subplot(1, 2, 1)
sns.countplot(y=column_name, data=df, palette='muted')
plt.title(f'Distribution of {column_name}')

ax = plt.gca()
for p in ax.patches:
    ax.annotate(f'{int(p.get_width())}', (p.get_width(), p.get_y() + p.get_height() / 2),
                ha='center', va='center', xytext=(10, 0), textcoords='offset points')

sns.despine(left=True, bottom=True)

# Second subplot: Pie chart
plt.subplot(1, 2, 2)
df[column_name].value_counts().plot.pie(autopct='%1.1f%%', colors=sns.color_palette('muted'), startangle=90, explode=[0.05]*df[column_name].nunique())
plt.title(f'Percentage Distribution of {column_name}')
plt.ylabel('')

plt.tight_layout()
plt.show()

# Function to perform univariate analysis for numeric columns
def univariate_analysis(data, columns):
    plt.figure(figsize=(10, 15))

    muted_colors = sns.color_palette("muted", len(columns))

    for i, column in enumerate(columns):
        plt.subplot(3, 2, i + 1)
        sns.histplot(data[column], kde=True, bins=10, color=muted_colors[i])
        plt.title(f'{column.replace("_", " ")} Distribution with KDE')
        plt.xlabel(column.replace('_', ' '))
        plt.ylabel('Frequency')

    plt.tight_layout()
    plt.show()

columns_to_analyze = ['Study_Hours_Per_Day', 'Extracurricular_Hours_Per_Day',
                       'Sleep_Hours_Per_Day', 'Social_Hours_Per_Day',
                       'Physical_Activity_Hours_Per_Day', 'GPA']

univariate_analysis(df, columns_to_analyze)

"""# **CLEANING DATA**"""

# Check for missing and duplicated values
print(f'\nMissing values: {df.isna().sum().sum()}')
print(f'Duplicated values: {df.duplicated().sum()}')

"""# **FEATURE SELECTION/ENGINEERING**"""

# prompt: create code for Feature Selection / Engineering

import pandas as pd
import numpy as np
# One-Hot Encode Categorical Features
# df = pd.get_dummies(df, columns=['Residence_Type', 'Diet_Type']) # These columns do not exist in the dataset

# Create Interaction Features
df['Study_Sleep_Interaction'] = df['Study_Hours_Per_Day'] * df['Sleep_Hours_Per_Day']
df['Physical_Social_Interaction'] = df['Physical_Activity_Hours_Per_Day'] * df['Social_Hours_Per_Day']

# Create Polynomial Features (example for GPA)
df['GPA_squared'] = df['GPA'] ** 2

# Binning (example for Study_Hours_Per_Day)
df['Study_Hours_Bin'] = pd.cut(df['Study_Hours_Per_Day'], bins=[0, 2, 4, 6, np.inf], labels=['Low', 'Medium', 'High', 'Very High'])
df = pd.get_dummies(df, columns=['Study_Hours_Bin'], prefix='Study_Hours')

# Drop original columns if their engineered features are preferred
# For instance, you might consider dropping the original 'Study_Hours_Per_Day' after binning, depending on your model
# df = df.drop('Study_Hours_Per_Day', axis=1)

display(df.head())
print("\nDataset Information after Feature Engineering:")
print(df.info())

"""# **SPLITTING DATA**"""

# prompt: create code for splitting data

# Assuming 'target_column' is the name of your target variable
X = df.drop('Stress_Level', axis=1) # Features
y = df['Stress_Level'] # Target variable
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
print("Shape of X_train:", X_train.shape)
print("Shape of X_test:", X_test.shape)
print("Shape of y_train:", y_train.shape)
print("Shape of y_test:", y_test.shape)

"""# **NAIVE BAYES**"""

# prompt: create code for Training data

import matplotlib.pyplot as plt
import numpy as np
# # **TRAINING DATA**

# Train the Random Forest model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42) # You can adjust n_estimators
rf_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred_rf = rf_model.predict(X_test)

# Evaluate the Random Forest model
print("Random Forest Classification Report:")
print(classification_report(y_test, y_pred_rf))

# Confusion Matrix for Random Forest
cm_rf = confusion_matrix(y_test, y_pred_rf)
disp_rf = ConfusionMatrixDisplay(confusion_matrix=cm_rf)
disp_rf.plot()
plt.title("Random Forest Confusion Matrix")
plt.show()

# Cross-validation for Random Forest
cv_scores_rf = cross_val_score(rf_model, X, y, cv=StratifiedKFold(n_splits=5))
print("\nRandom Forest Cross-validation scores (5-fold stratified):", cv_scores_rf)
print("Mean cross-validation score:", np.mean(cv_scores_rf))

# Train the Logistic Regression model
lr_model = LogisticRegression(random_state=42, solver='liblinear') # solver='liblinear' is good for small datasets
lr_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred_lr = lr_model.predict(X_test)

# Evaluate the Logistic Regression model
print("\nLogistic Regression Classification Report:")
print(classification_report(y_test, y_pred_lr))

# Confusion Matrix for Logistic Regression
cm_lr = confusion_matrix(y_test, y_pred_lr)
disp_lr = ConfusionMatrixDisplay(confusion_matrix=cm_lr)
disp_lr.plot()
plt.title("Logistic Regression Confusion Matrix")
plt.show()

# Cross-validation for Logistic Regression
cv_scores_lr = cross_val_score(lr_model, X, y, cv=StratifiedKFold(n_splits=5))
print("\nLogistic Regression Cross-validation scores (5-fold stratified):", cv_scores_lr)
print("Mean cross-validation score:", np.mean(cv_scores_lr))


# # **STACKING MODEL**
# Define base models
estimators = [
    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),
    ('lr', LogisticRegression(random_state=42, solver='liblinear')),
    ('gnb', GaussianNB()) # Include Naive Bayes as a base model
]

# Define the meta-model
# Logistic Regression is often a good choice for the meta-model
stacking_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(random_state=42))

# Train the Stacking model
stacking_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred_stack = stacking_model.predict(X_test)

# Evaluate the Stacking model
print("\nStacking Classifier Classification Report:")
print(classification_report(y_test, y_pred_stack))

# Confusion Matrix for Stacking Classifier
cm_stack = confusion_matrix(y_test, y_pred_stack)
disp_stack = ConfusionMatrixDisplay(confusion_matrix=cm_stack)
disp_stack.plot()
plt.title("Stacking Classifier Confusion Matrix")
plt.show()

# Cross-validation for Stacking Classifier
# Note: Cross-validation for StackingClassifiers can be computationally expensive
cv_scores_stack = cross_val_score(stacking_model, X, y, cv=StratifiedKFold(n_splits=5))
print("\nStacking Classifier Cross-validation scores (5-fold stratified):", cv_scores_stack)
print("Mean cross-validation score:", np.mean(cv_scores_stack))

# prompt: create code for naive bayes from training data

import matplotlib.pyplot as plt
import numpy as np
from sklearn.naive_bayes import GaussianNB

# Initialize and train the Naive Bayes model
nb_model = GaussianNB()
nb_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred_nb = nb_model.predict(X_test)

# Evaluate the Naive Bayes model
print("\nNaive Bayes Classification Report:")
print(classification_report(y_test, y_pred_nb))

# Confusion Matrix for Naive Bayes
cm_nb = confusion_matrix(y_test, y_pred_nb)
disp_nb = ConfusionMatrixDisplay(confusion_matrix=cm_nb)
disp_nb.plot()
plt.title("Naive Bayes Confusion Matrix")
plt.show()

# Cross-validation for Naive Bayes
cv_scores_nb = cross_val_score(nb_model, X, y, cv=StratifiedKFold(n_splits=5))
print("\nNaive Bayes Cross-validation scores (5-fold stratified):", cv_scores_nb)
print("Mean cross-validation score:", np.mean(cv_scores_nb))

"""## **SAVE DATA**"""

# prompt: CREATE CODE FOR SAVE DATA pkl

import pickle

# Save the best performing model (e.g., the stacking_model)
# Replace 'stacking_model' with the variable name of the model you want to save
model_to_save = stacking_model # Or rf_model, lr_model, nb_model based on performance

# Define the file path to save the model (adjust the path as needed)
# This assumes you have already mounted Google Drive using the preceding code
save_path = Path + '/best_stress_prediction_model.pkl'

with open(save_path, 'wb') as f:
    pickle.dump(model_to_save, f)

print(f"Model saved to {save_path}")

# Example of how to load the model back later
# with open(save_path, 'rb') as f:
#     loaded_model = pickle.load(f)
# print("\nModel loaded successfully!")